# Gesture Bass Synth

손 제스처를 사용하여 연주하는 인터랙티브 웹 기반 신디사이저입니다. 웹캠을 통해 손의 움직임을 감지하고, 이를 소리의 높낮이와 음색 변화로 변환합니다.

## 사용 방법 (User Guide)

1. **시작하기**: 웹앱을 실행하고 화면 중앙의 하단에 있는 **Start Audio** 버튼을 클릭하여 오디오 시스템을 활성화합니다.
2. **손 인식**: 웹캠에 손을 비주세요. 화면에 손의 뼈대가 빨간색 선으로 표시됩니다.
3. **연주하기 (Trigger)**: 엄지손가락과 검지손가락을 맞대어 **꼬집는 동작(Pinch)**을 취하면 소리가 납니다. 손가락을 떼면 소리가 멈춥니다.
4. **음계 조절 (Pitch)**: 꼬집은 상태에서 손을 **좌우(X축)**로 움직여 음의 높 낮이를 조절합니다. (왼쪽 높은 음 <-> 오른쪽 낮은 음, 미러링 적용으로 인해 반전될 수 있음)
   - 스케일: D Dorian Mode (2 옥타브)
5. **필터 조절 (Filter)**: 꼬집은 상태에서 손을 **위아래(Y축)**로 움직여 소리의 밝기(Filter Frequency)를 조절합니다.

## 작동 원리 (Mechanics)

이 프로젝트는 다음의 핵심 웹 기술과 라이브러리를 사용하여 작동합니다:

### 1. 라이브러리 스택
- **p5.js**: 캔버스 드로잉, 비디오 피드 처리, 시각화 담당.
- **ml5.js**: 브라우저 기반 머신러닝. `handPose` 모델을 사용하여 실시간으로 손의 랜드마크(Keypoints)를 추적합니다.
- **Tone.js**: 웹 오디오 API 래퍼. 신디사이저(MonoSynth), 이펙트(Distortion, Chorus) 및 오디오 스케줄링을 담당합니다.

### 2. 기술적 세부 사항 (For Agents & Developers)
- **비디오 처리**: 웹캠 피드(640x480)를 가져와 캔버스 크기에 맞춰 비율을 유지하며 꽉 채우는(Cover) 방식으로 렌더링합니다. 사용자 경험을 위해 좌우 반전(Mirroring) 처리되어 있습니다.
- **좌표 매핑**:
  - `ml5.handPose`는 원본 비디오 해상도(640x480) 기준의 좌표를 반환합니다.
  - 시각화 및 인터랙션 로직에서 이 좌표를 현재 윈도우 크기에 맞게 Scaling 및 Translation 하여 변환합니다.
- **오디오 로직**:
  - **Synth**: Sawtooth 파형을 사용하는 `Tone.MonoSynth`입니다.
  - **Effects**: `Tone.Distortion` (약한 왜곡) -> `Tone.Chorus` (공간감) 체인이 연결되어 있습니다.
  - **Trigger**: 엄지(4번 키포인트)와 검지 끝(8번 키포인트) 사이의 유클리드 거리가 임계값(30px) 이하일 때 `triggerAttack`, 이상일 때 `triggerRelease`가 실행됩니다.
  - **Parameters**: 
    - Pitch: 엄지의 X 좌표를 매핑하여 `scaleNotes` 배열의 인덱스를 선택합니다.
    - Filter: 엄지의 Y 좌표를 매핑하여 `baseFrequency`를 100Hz ~ 5000Hz 사이로 조절합니다.

## 파일 구조
- `index.html`: UI 구조 및 라이브러리 로드.
- `script.js`: 주요 로직 (비디오 처리, 손 인식, 오디오 합성, 인터랙션).
- `style.css`: 레이아웃 및 스타일링.
